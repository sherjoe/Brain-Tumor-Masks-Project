{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11957028,"sourceType":"datasetVersion","datasetId":7517886},{"sourceId":13951199,"sourceType":"datasetVersion","datasetId":8827899}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Brain Tumors MRIs Segmentation Masks vs CNN Grad-cam ++ Saliency Masks : \n\n# *Which Texture Features For Each Tumor Image Will Potential Radiomic Biomarkers Show Up?*","metadata":{}},{"cell_type":"markdown","source":"Used Datasets : • Masoud Nickparvar, Kaggle Brain Tumor Dataset, 2020.\n                • SciDB Brain Tumor Dataset, SciDB, 2021.\nIndrakumar K, and Ravikumar M. (2025). Brain Tumor Dataset: Segmentation & Classification [Data set]. Kaggle. https://doi.org/10.34740/KAGGLE/DSV/11957028","metadata":{}},{"cell_type":"markdown","source":"### Firstly, install dependencies...","metadata":{}},{"cell_type":"code","source":"!pip install pyradiomics\n!pip install SimpleITK","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T23:10:56.876499Z","iopub.execute_input":"2025-12-01T23:10:56.876695Z","iopub.status.idle":"2025-12-01T23:11:20.476620Z","shell.execute_reply.started":"2025-12-01T23:10:56.876678Z","shell.execute_reply":"2025-12-01T23:11:20.475708Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### And load the imports...","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nimport SimpleITK as sitk\nfrom radiomics import featureextractor\nfrom sklearn.feature_selection import VarianceThreshold, f_classif\nfrom sklearn.preprocessing import LabelEncoder\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport shap\nfrom keras.models import Sequential \nfrom keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Input, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom keras.metrics import Accuracy, Precision, F1Score\nfrom keras.models import Model \nimport random\nimport os\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import wilcoxon\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.applications.mobilenet_v2 import MobileNetV2\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T23:17:24.106522Z","iopub.execute_input":"2025-12-01T23:17:24.106795Z","iopub.status.idle":"2025-12-01T23:17:24.113135Z","shell.execute_reply.started":"2025-12-01T23:17:24.106778Z","shell.execute_reply":"2025-12-01T23:17:24.112285Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This segmentation dataset contains three types of brain tumors : glioma, meningioma, and pituitary. Each mask per image has already beem provided, where Pyradiomics's feature extractor will only focus on that masked region of the tumor (not focused on the background of the image), and find interesting biological details about its texture surrounding the region.","metadata":{}},{"cell_type":"markdown","source":"**This imaging dataset has already been preprocessed to have noise reduction and is normalized.**","metadata":{}},{"cell_type":"code","source":"csv_file = \"/kaggle/input/brain-tumor-classes/tumor_segment.csv\"\n\ndata = pd.read_csv(csv_file)\n\nclass_distribution = data['class_name'].value_counts()\nprint(class_distribution)\n\nplt.figure(figsize=(10,6))\nclass_distribution.plot(kind = 'bar', color='violet')\nplt.title('Class Distribution')\nplt.xlabel('Class Label')\nplt.ylabel(\"Number of Images\")\nplt.xticks(rotation = 45)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T18:42:11.628415Z","iopub.execute_input":"2025-12-01T18:42:11.629195Z","iopub.status.idle":"2025-12-01T18:42:11.979388Z","shell.execute_reply.started":"2025-12-01T18:42:11.629167Z","shell.execute_reply":"2025-12-01T18:42:11.978699Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T18:42:11.980113Z","iopub.execute_input":"2025-12-01T18:42:11.980346Z","iopub.status.idle":"2025-12-01T18:42:11.998004Z","shell.execute_reply.started":"2025-12-01T18:42:11.980328Z","shell.execute_reply":"2025-12-01T18:42:11.997437Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **An example of a 2D Glioma tumor and its designated segmentation mask :**","metadata":{}},{"cell_type":"code","source":"image_path_mri = \"/kaggle/input/brain-tumor-dataset-segmentation-and-classification/DATASET/Segmentation/Glioma/enh_1841.png\"\nimage_path_mask = \"/kaggle/input/brain-tumor-dataset-segmentation-and-classification/DATASET/Segmentation/Glioma/enh_1841_mask.png\"\n\nimg_mri = Image.open(image_path_mri)\nimg_mask = Image.open(image_path_mask)\n\nplt.imshow(img_mri)    #MRI example\nplt.axis('on')\nplt.show\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T18:42:11.998842Z","iopub.execute_input":"2025-12-01T18:42:11.999595Z","iopub.status.idle":"2025-12-01T18:42:12.293582Z","shell.execute_reply.started":"2025-12-01T18:42:11.999567Z","shell.execute_reply":"2025-12-01T18:42:12.292936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(img_mask)\nplt.axis('on')        #Mask example\nplt.show","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T18:42:12.294382Z","iopub.execute_input":"2025-12-01T18:42:12.294985Z","iopub.status.idle":"2025-12-01T18:42:12.466919Z","shell.execute_reply.started":"2025-12-01T18:42:12.294961Z","shell.execute_reply":"2025-12-01T18:42:12.466339Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Now lets extract those texture features from all of these masks from the dataset...","metadata":{}},{"cell_type":"code","source":"seg_dir = \"/kaggle/input/brain-tumor-dataset-segmentation-and-classification/DATASET/Segmentation\"\ntumors = [\"Glioma\", \"Meningioma\", \"Pituitary tumor\"] #What the folders say...\n\nextractor = featureextractor.RadiomicsFeatureExtractor()\nextractor.enableAllFeatures() \nseg_images = []\n\nfor tumor in tumors:\n    folder_path = os.path.join(seg_dir, tumor)\n\n    for file in os.listdir(folder_path):\n        if \"mask\" in file:  \n            continue\n\n        img_path = os.path.join(folder_path, file)\n        mask_path = os.path.join(folder_path, file.replace('.png', '_mask.png'))\n        image = sitk.ReadImage(img_path)\n        mask = sitk.ReadImage(mask_path)\n       \n        feature_vector = extractor.execute(image, mask, label = 255) #Change size to 255 pixels\n      \n        feature_vector[\"tumor_type\"] = tumor\n        feature_vector[\"file_name\"] = file\n        seg_images.append(feature_vector) #Vectors\n\nseg_images_df = pd.DataFrame(seg_images)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T18:42:12.470963Z","iopub.execute_input":"2025-12-01T18:42:12.471391Z","iopub.status.idle":"2025-12-01T18:46:41.525262Z","shell.execute_reply.started":"2025-12-01T18:42:12.471362Z","shell.execute_reply":"2025-12-01T18:46:41.524651Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seg_images_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T18:46:41.526200Z","iopub.execute_input":"2025-12-01T18:46:41.526495Z","iopub.status.idle":"2025-12-01T18:46:41.550270Z","shell.execute_reply.started":"2025-12-01T18:46:41.526469Z","shell.execute_reply":"2025-12-01T18:46:41.549526Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features = seg_images_df.drop(columns=['file_name', 'tumor_type'])\nlabel = seg_images_df['tumor_type']\n\nprint(features.shape, label.shape) #The tumor is what we are associating everything else for","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T18:46:41.551049Z","iopub.execute_input":"2025-12-01T18:46:41.551531Z","iopub.status.idle":"2025-12-01T18:46:41.583510Z","shell.execute_reply.started":"2025-12-01T18:46:41.551512Z","shell.execute_reply":"2025-12-01T18:46:41.582884Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cols_to_drop = [col for col in features.columns if col.startswith('diagnostics_')]\nfeatures = features.drop(columns=cols_to_drop)\n\nfeatures = features.select_dtypes(include=[np.number])\nprint(features.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T18:46:41.584209Z","iopub.execute_input":"2025-12-01T18:46:41.584512Z","iopub.status.idle":"2025-12-01T18:46:41.601855Z","shell.execute_reply.started":"2025-12-01T18:46:41.584494Z","shell.execute_reply":"2025-12-01T18:46:41.601139Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"selector = VarianceThreshold(threshold=0.01)\nfeatures_reduced = selector.fit_transform(features)\n\nselect = features.columns[selector.get_support()]\nfeatures = pd.DataFrame(features_reduced, columns = select)\n\nprint(features.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T18:46:41.602758Z","iopub.execute_input":"2025-12-01T18:46:41.603073Z","iopub.status.idle":"2025-12-01T18:46:41.610878Z","shell.execute_reply.started":"2025-12-01T18:46:41.603054Z","shell.execute_reply":"2025-12-01T18:46:41.610268Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom xgboost import XGBClassifier\n\nle = LabelEncoder()\nlabel_encoded = le.fit_transform(label)\n\nxgb = XGBClassifier(n_estimators=200, random_state=42, use_label_encoder=False, eval_metric='logloss') \nxgb.fit(features, label_encoded)\n\ntop_features = pd.DataFrame({\n    'Feature': features.columns,\n    'Importance': xgb.feature_importances_\n}).sort_values('Importance', ascending=False)\n\n\nprint(top_features.head(15))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T18:46:41.611546Z","iopub.execute_input":"2025-12-01T18:46:41.611707Z","iopub.status.idle":"2025-12-01T18:46:42.100281Z","shell.execute_reply.started":"2025-12-01T18:46:41.611694Z","shell.execute_reply":"2025-12-01T18:46:42.099455Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"explainer = shap.TreeExplainer(xgb)\nshap_values = explainer.shap_values(features)\n\nshap.summary_plot(shap_values, features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T18:46:42.101319Z","iopub.execute_input":"2025-12-01T18:46:42.101609Z","iopub.status.idle":"2025-12-01T18:46:44.850788Z","shell.execute_reply.started":"2025-12-01T18:46:42.101581Z","shell.execute_reply":"2025-12-01T18:46:44.850162Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"original_labels = le.inverse_transform(xgb.classes_) #fyi...\nprint(original_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T18:46:44.851524Z","iopub.execute_input":"2025-12-01T18:46:44.851789Z","iopub.status.idle":"2025-12-01T18:46:44.856578Z","shell.execute_reply.started":"2025-12-01T18:46:44.851764Z","shell.execute_reply":"2025-12-01T18:46:44.855788Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\ntop_features.head(20).plot(kind='bar', x='Feature', y='Importance')\nplt.title(\"Top 20 Radiomic Feature Importances\")\nplt.ylabel(\"Importance Score\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T18:46:44.857418Z","iopub.execute_input":"2025-12-01T18:46:44.857785Z","iopub.status.idle":"2025-12-01T18:46:45.038855Z","shell.execute_reply.started":"2025-12-01T18:46:44.857760Z","shell.execute_reply":"2025-12-01T18:46:45.038071Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"F, p = f_classif(features, label)\n\nanova_results = pd.DataFrame({\n    \"Feature\": features.columns,    #anova also pulls out the same names as xgboost in a different order...\n    \"p-value\": p,\n    \"F-score\": F\n}).sort_values(\"p-value\").reset_index(drop=True)\n\nanova_results.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T18:46:45.040344Z","iopub.execute_input":"2025-12-01T18:46:45.040595Z","iopub.status.idle":"2025-12-01T18:46:45.058671Z","shell.execute_reply.started":"2025-12-01T18:46:45.040577Z","shell.execute_reply":"2025-12-01T18:46:45.058150Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for shap_class, cls in zip(shap_values, xgb.classes_):\n    print(f\"Top features for class: {cls}\")\n    shap.summary_plot(shap_class, features, feature_names=features.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T18:46:45.059235Z","iopub.execute_input":"2025-12-01T18:46:45.059408Z","iopub.status.idle":"2025-12-01T18:46:45.811766Z","shell.execute_reply.started":"2025-12-01T18:46:45.059393Z","shell.execute_reply":"2025-12-01T18:46:45.811083Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## We can conclude that original_shape2D_MajorAxisLength, original_shape2D_MinorAxisLength, original_shape2D_PixelSurface, and original_shape2D_Elongation are the deciding factors that identifies a specific tumor based on its 2D textures.","metadata":{}},{"cell_type":"markdown","source":"But then what does a CNN classfier take from these ROIs (regions of interest that makes up a brain tumor identification), when it performs its own analysis looking for relevant texture features??","metadata":{}},{"cell_type":"markdown","source":"#### This classfication dataset has a new class 'notumor' where the classfier is expected to differentiate between healthy brains and ones with glioma, meningioma, or pituitary.","metadata":{}},{"cell_type":"code","source":"csv_file = \"/kaggle/input/brain-tumor-classes/tumor_class_train.csv\"\n\ndata_class = pd.read_csv(csv_file)\n\nclass_distribution = data_class['class_name'].value_counts()\nprint(class_distribution)\n\nplt.figure(figsize=(10,6))\nclass_distribution.plot(kind = 'bar', color='lime')\nplt.title('Class Distribution')\nplt.xlabel('Class Label')\nplt.ylabel(\"Number of Images\")\nplt.xticks(rotation = 45)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:36:16.758554Z","iopub.execute_input":"2025-12-01T21:36:16.759454Z","iopub.status.idle":"2025-12-01T21:36:17.063694Z","shell.execute_reply.started":"2025-12-01T21:36:16.759426Z","shell.execute_reply":"2025-12-01T21:36:17.063072Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_class.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:36:19.224948Z","iopub.execute_input":"2025-12-01T21:36:19.225523Z","iopub.status.idle":"2025-12-01T21:36:19.243365Z","shell.execute_reply.started":"2025-12-01T21:36:19.225494Z","shell.execute_reply":"2025-12-01T21:36:19.242369Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **The Four Classes of Brain Tumors :**","metadata":{}},{"cell_type":"code","source":"selected_images = data_class.groupby('class_name')['image_path'].first().reset_index()\n\nfrom PIL import Image\n\nfor _, row in selected_images.iterrows():\n    className = row['class_name']\n    imagePath = row['image_path']\n    imageFile = os.path.join('/kaggle/input/brain-tumor-dataset-segmentation-and-classification/DATASET/classification/Training', imagePath)\n    image = Image.open(imageFile)\n\n    plt.figure()\n    plt.imshow(image)\n    plt.title(f'Class: {className}')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:36:21.452756Z","iopub.execute_input":"2025-12-01T21:36:21.453353Z","iopub.status.idle":"2025-12-01T21:36:22.365796Z","shell.execute_reply.started":"2025-12-01T21:36:21.453326Z","shell.execute_reply":"2025-12-01T21:36:22.365175Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Now, lets preprocess these images so we can fine tune our pre-trained CNN without background artifacts...","metadata":{}},{"cell_type":"code","source":"def add_gaussian_blur(img):\n    img = cv2.GaussianBlur(img, (3,3), 0)\n    return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:06:23.551745Z","iopub.execute_input":"2025-12-01T21:06:23.552377Z","iopub.status.idle":"2025-12-01T21:06:23.556037Z","shell.execute_reply.started":"2025-12-01T21:06:23.552354Z","shell.execute_reply":"2025-12-01T21:06:23.555299Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df, validate_df = train_test_split(data_class, test_size=0.20, random_state=42)\n\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)\n\nbatch_size = 20\nimg_height = 224\nimg_width = 224\n\ntrain_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rotation_range=10, \n    rescale=1./255, \n    shear_range=0.2, \n    zoom_range=0.10, \n    horizontal_flip=True, \n    brightness_range=[1.1, 1.2]\n)\n\nvalidation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=\"/kaggle/input/brain-tumor-dataset-segmentation-and-classification/DATASET/classification/Training\",\n    x_col=\"image_path\",  \n    y_col=\"class_name\",  \n    target_size=(img_height, img_width), \n    batch_size=batch_size,\n    shuffle=True ,\n    class_mode=\"categorical\" \n)\n\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    dataframe=validate_df,\n    directory=\"/kaggle/input/brain-tumor-dataset-segmentation-and-classification/DATASET/classification/Training\",\n    x_col=\"image_path\",\n    y_col=\"class_name\",\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    shuffle=False ,\n    class_mode=\"categorical\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:36:27.124148Z","iopub.execute_input":"2025-12-01T21:36:27.124826Z","iopub.status.idle":"2025-12-01T21:36:35.424342Z","shell.execute_reply.started":"2025-12-01T21:36:27.124800Z","shell.execute_reply":"2025-12-01T21:36:35.423782Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dir = '/kaggle/input/brain-tumor-dataset-segmentation-and-classification/DATASET/classification/Testing'\ntest_csv_path = '/kaggle/input/brain-tumor-classes/tumor_class_test.csv'\ntest_df = pd.read_csv(test_csv_path)\n\ntest_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    test_df,\n    test_dir,\n    x_col=\"image_path\",\n    y_col=\"class_name\",\n    target_size=(img_height, img_width),\n    batch_size=1, #Better for plotting\n    shuffle=False,\n    class_mode=\"categorical\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:36:38.155092Z","iopub.execute_input":"2025-12-01T21:36:38.155379Z","iopub.status.idle":"2025-12-01T21:36:40.040559Z","shell.execute_reply.started":"2025-12-01T21:36:38.155357Z","shell.execute_reply":"2025-12-01T21:36:40.039754Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Much better for the model.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimages, labels = next(train_generator)\n\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n    ax = plt.subplot(3, 3, i + 1)   #New preprocessed MRI images\n    plt.imshow(images[i])\n    plt.title(f'Class: {labels[i]}')\n    plt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:36:42.992411Z","iopub.execute_input":"2025-12-01T21:36:42.992989Z","iopub.status.idle":"2025-12-01T21:36:43.951012Z","shell.execute_reply.started":"2025-12-01T21:36:42.992964Z","shell.execute_reply":"2025-12-01T21:36:43.950208Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_names = list(train_generator.class_indices.keys())\nprint(\"Class Names:\", class_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:39:59.303777Z","iopub.execute_input":"2025-12-01T20:39:59.304211Z","iopub.status.idle":"2025-12-01T20:39:59.308145Z","shell.execute_reply.started":"2025-12-01T20:39:59.304189Z","shell.execute_reply":"2025-12-01T20:39:59.307394Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Now time to train our MobileNetV2 CNN model...","metadata":{}},{"cell_type":"code","source":"input_shape = (img_height, img_width, 3)\n\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\nfor layer in base_model.layers:\n    layer.trainable = False\n    \nnum_layers_to_unfreeze = 50\n\nfor layer in base_model.layers[-num_layers_to_unfreeze:]:\n    layer.trainable = True\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)  \nx = Dense(1024, activation='relu')(x)  \npredictions = Dense(4, activation='softmax')(x)  \n\n\nmodel = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n\nmodel.compile(optimizer=Adam(learning_rate=0.0001), \n              loss='categorical_crossentropy', \n              metrics=['accuracy'])\nmodel.fit(train_generator, epochs= 5, validation_data=validation_generator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:36:49.520872Z","iopub.execute_input":"2025-12-01T21:36:49.521457Z","iopub.status.idle":"2025-12-01T21:42:52.499886Z","shell.execute_reply.started":"2025-12-01T21:36:49.521432Z","shell.execute_reply":"2025-12-01T21:42:52.499320Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"first_test_predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size + 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:44:20.824027Z","iopub.execute_input":"2025-12-01T21:44:20.824729Z","iopub.status.idle":"2025-12-01T21:44:34.915846Z","shell.execute_reply.started":"2025-12-01T21:44:20.824705Z","shell.execute_reply":"2025-12-01T21:44:34.914994Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predicted_labels = np.argmax(first_test_predictions, axis=1)\ntrue_labels = test_generator.classes\ncm = confusion_matrix(true_labels, predicted_labels)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_generator.class_indices.keys())\ndisp.plot()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:44:37.078334Z","iopub.execute_input":"2025-12-01T21:44:37.078847Z","iopub.status.idle":"2025-12-01T21:44:37.267672Z","shell.execute_reply.started":"2025-12-01T21:44:37.078821Z","shell.execute_reply":"2025-12-01T21:44:37.267013Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Implementing Gradcam++","metadata":{}},{"cell_type":"markdown","source":"The difference bewteen Gradcam and Gradcam++ is that Gradcam++ focuses more on the pixels that make up the ROI and weighs them more, while Gradcam just puts weights on the whole ROI.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\ndef grad_cam_plus_plus(model, img_array, layer_name):\n    grad_model = tf.keras.models.Model(\n        [model.inputs], \n        [model.get_layer(layer_name).output, model.output] #get conv layer feature maps\n    )\n\n    with tf.GradientTape() as tape:\n        conv_output, predictions = grad_model(img_array)\n        pred_index = tf.argmax(predictions[0])\n        class_channel = predictions[:, pred_index]\n\n    grads = tape.gradient(class_channel, conv_output) \n\n    numerator = grads ** 2\n    denominator = 2 * grads ** 2 + tf.reduce_sum(conv_output * grads, axis=(1, 2), keepdims=True)   #weights on the pixels that make up the ROI  \n    alpha = numerator / (denominator + 1e-10)\n\n    weights = tf.reduce_sum(alpha * tf.nn.relu(grads), axis=(1, 2))\n    cam = tf.reduce_sum(weights * conv_output, axis=-1).numpy()\n\n    cam = np.maximum(cam, 0)\n    cam = cam[0]  \n\n    cam = cv2.resize(cam, (img_width, img_height))\n    cam = cam / cam.max() #resize and normalize\n    return cam","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:44:45.032743Z","iopub.execute_input":"2025-12-01T21:44:45.033026Z","iopub.status.idle":"2025-12-01T21:44:45.039541Z","shell.execute_reply.started":"2025-12-01T21:44:45.033006Z","shell.execute_reply":"2025-12-01T21:44:45.038831Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"last_conv_layer = None\nfor layer in reversed(model.layers):\n    if isinstance(layer, tf.keras.layers.Conv2D):\n        last_conv_layer = layer.name\n        break\n\nprint(last_conv_layer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:44:48.834427Z","iopub.execute_input":"2025-12-01T21:44:48.834754Z","iopub.status.idle":"2025-12-01T21:44:48.839566Z","shell.execute_reply.started":"2025-12-01T21:44:48.834731Z","shell.execute_reply":"2025-12-01T21:44:48.838691Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_generator.reset() #running predictions again...\n\npredictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size + 1)\npredicted_labels = np.argmax(predictions, axis=1)\n\ntrue_labels = test_generator.classes \nclass_names = list(test_generator.class_indices.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:44:51.627171Z","iopub.execute_input":"2025-12-01T21:44:51.627445Z","iopub.status.idle":"2025-12-01T21:44:58.747404Z","shell.execute_reply.started":"2025-12-01T21:44:51.627422Z","shell.execute_reply":"2025-12-01T21:44:58.746659Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"correct_images = []\ncorrect_pred_labels = []\n\ntest_generator.reset()\n\nfor i in range(test_generator.samples):\n    img_batch = next(test_generator)[0]\n    img = img_batch[0]\n    \n    if predicted_labels[i] == true_labels[i]: \n        correct_images.append(img)\n        correct_pred_labels.append(predicted_labels[i])\n\n    if len(correct_images) >= 1200: \n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:45:01.958189Z","iopub.execute_input":"2025-12-01T21:45:01.958920Z","iopub.status.idle":"2025-12-01T21:45:05.312918Z","shell.execute_reply.started":"2025-12-01T21:45:01.958892Z","shell.execute_reply":"2025-12-01T21:45:05.312322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"correct_heatmaps = []\n\nfor img in correct_images:\n    img_input = np.expand_dims(img, axis=0)\n    heatmap = grad_cam_plus_plus(model, img_input, last_conv_layer)\n    correct_heatmaps.append(heatmap)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:45:09.003373Z","iopub.execute_input":"2025-12-01T21:45:09.004136Z","iopub.status.idle":"2025-12-01T21:50:43.797477Z","shell.execute_reply.started":"2025-12-01T21:45:09.004105Z","shell.execute_reply":"2025-12-01T21:50:43.796837Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_saliency_mask(heatmap, tumor_mask=None, percentile=90):\n    \n    if tumor_mask is not None:  \n        night_vision = np.percentile(heatmap[tumor_mask > 0], percentile)\n        saliency_mask = (heatmap > night_vision) & (tumor_mask > 0)\n    else:                                                     #like the segmented masks we dont pay attention towards the background\n        night_vision = np.percentile(heatmap, percentile)\n        saliency_mask = (heatmap > night_vision)\n\n    return saliency_mask.astype(np.uint8)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:50:54.436530Z","iopub.execute_input":"2025-12-01T21:50:54.437278Z","iopub.status.idle":"2025-12-01T21:50:54.441639Z","shell.execute_reply.started":"2025-12-01T21:50:54.437251Z","shell.execute_reply":"2025-12-01T21:50:54.440835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\n\ndef generate_pseudo_mask(img):\n    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY) #grayscale\n\n    threshold_value, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    #print(\"threshold:\", threshold_value)\n\n    kernel = np.ones((5, 5), np.uint8) \n    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n    \n    return (mask > 0).astype(np.uint8) \n    \nsaliency_masks = []\n\nfor i, (heatmap, pred_label) in enumerate(zip(correct_heatmaps, correct_pred_labels)):\n    \n    class_name = class_names[pred_label]\n    \n    if class_name != 'notumor': \n        tumor_mask = generate_pseudo_mask(correct_images[i]) \n    else:\n        tumor_mask = None \n\n    mask = get_saliency_mask(heatmap, tumor_mask, percentile=90)\n    saliency_masks.append(mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:51:01.779208Z","iopub.execute_input":"2025-12-01T21:51:01.779951Z","iopub.status.idle":"2025-12-01T21:51:02.718341Z","shell.execute_reply.started":"2025-12-01T21:51:01.779924Z","shell.execute_reply":"2025-12-01T21:51:02.717478Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_count = 10\nplot_images = correct_images[:image_count]\nplot_labels = correct_pred_labels[:image_count]\nplot_heatmaps = correct_heatmaps[:image_count]\nplot_saliency = saliency_masks[:image_count]\n\nplt.figure(figsize=(10, 40))\n\nfor i in range(image_count):\n    plt.subplot(image_count, 3, 3*i + 1)\n    plt.imshow(plot_images[i])\n    plt.title(f\"Image: {class_names[plot_labels[i]]}\")\n    plt.axis('off')\n\n    plt.subplot(image_count, 3, 3*i + 2)\n    plt.imshow(plot_heatmaps[i], cmap='jet')\n    plt.title(\"Grad-Cam++ Heatmap\")\n    plt.axis('off')\n\n    plt.subplot(image_count, 3, 3*i + 3)\n    plt.imshow(plot_images[i])\n    plt.imshow(plot_saliency[i], alpha=0.4, cmap='jet')\n    plt.title(\"Saliency Mask\")\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:51:05.820783Z","iopub.execute_input":"2025-12-01T21:51:05.821485Z","iopub.status.idle":"2025-12-01T21:51:09.361375Z","shell.execute_reply.started":"2025-12-01T21:51:05.821438Z","shell.execute_reply":"2025-12-01T21:51:09.360527Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```\nimport cv2\nimport numpy as np\nimport nibabel as nib\n\ndef save_jpg_as_nifti(jpg_path, nii_path):\n    img = cv2.imread(jpg_path, cv2.IMREAD_GRAYSCALE) \n    img = img.astype(np.float32)\n\n    affine = np.eye(4)\n\n    nii_img = nib.Nifti1Image(img, affine)\n    nib.save(nii_img, nii_path)\n    print(f\"Saved MRI NIfTI: {nii_path}\")\n```","metadata":{}},{"cell_type":"markdown","source":"```\ndef save_mask_nifti(mask, reference_nii_path, out_path):\n    ref_nii = nib.load(reference_nii_path)\n    affine = ref_nii.affine \n\n    mask_nii = nib.Nifti1Image(mask.astype(np.uint8), affine)\n    nib.save(mask_nii, out_path)\n    print(f\"Saved mask: {out_path}\")\n```","metadata":{}},{"cell_type":"markdown","source":"```\nimport os\nimport cv2\nimport numpy as np\nimport nibabel as nib\n\noutput_dir = \"radiomics_ready/\"\nos.makedirs(output_dir, exist_ok=True)\n\ndef save_jpg_as_nifti(jpg_path, nii_path):\n    img = cv2.imread(jpg_path, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n\n    affine = np.eye(4)            \n    nii = nib.Nifti1Image(img, affine)\n\n    nib.save(nii, nii_path)\n\ndef save_mask_nifti(mask, ref_nii_path, out_path):\n    ref = nib.load(ref_nii_path)\n    nii = nib.Nifti1Image(mask.astype(np.uint8), ref.affine)\n    nib.save(nii, out_path)\n\nfor index, (img, heatmap, pred) in enumerate(zip(correct_images, correct_heatmaps, correct_pred_labels)):\n\n    class_name = class_names[pred]\n    jpg_path   = test_generator.filepaths[index]   \n    print(f\"Processing: {jpg_path}\")\n\n    mri_nii_path = os.path.join(output_dir, f\"{index:03d}_{class_name}_MRI.nii.gz\")\n    save_jpg_as_nifti(jpg_path, mri_nii_path)\n\n    if class_name != 'notumor':\n        tumor_mask = generate_pseudo_mask(img)  \n    else:\n        tumor_mask = None\n\n    saliency_mask = get_saliency_mask(heatmap, tumor_mask, percentile=90)\n\n    mask_nii_path = os.path.join(output_dir, f\"{index:03d}_{class_name}_saliency_mask.nii.gz\")\n    save_mask_nifti(saliency_mask, mri_nii_path, mask_nii_path)\n\n    print(f\"Saved: {mri_nii_path}  |  {mask_nii_path}\")\n\n```","metadata":{}},{"cell_type":"code","source":"plt.style.use('default')\nsns.set_theme(style=\"whitegrid\")\n\ndf_comparsion = pd.read_csv(\"/kaggle/input/brain-tumor-classes/Class_radiomics_saliency_comparison.csv\")\n\ndf_comparsion.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T23:12:56.411205Z","iopub.execute_input":"2025-12-01T23:12:56.412072Z","iopub.status.idle":"2025-12-01T23:12:56.577457Z","shell.execute_reply.started":"2025-12-01T23:12:56.412043Z","shell.execute_reply":"2025-12-01T23:12:56.576614Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_clean = df_comparsion.copy() \n\ndiag_cols = df_clean.filter(regex='diagnostics').columns\ndf_clean = df_clean.drop(columns=diag_cols)\n\ndf_clean = df_clean.select_dtypes(include=['float64', 'int64'])\n\nprint(df_clean.shape)\ndf_clean.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T23:13:46.524532Z","iopub.execute_input":"2025-12-01T23:13:46.524777Z","iopub.status.idle":"2025-12-01T23:13:46.547190Z","shell.execute_reply.started":"2025-12-01T23:13:46.524754Z","shell.execute_reply":"2025-12-01T23:13:46.546663Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_clean[\"TumorType\"] = df_comparsion[\"ID\"].apply(lambda x: x.split(\"_\")[1])\ndf_clean[\"TumorType\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T23:14:34.218319Z","iopub.execute_input":"2025-12-01T23:14:34.218914Z","iopub.status.idle":"2025-12-01T23:14:34.234193Z","shell.execute_reply.started":"2025-12-01T23:14:34.218887Z","shell.execute_reply":"2025-12-01T23:14:34.233498Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_cols = df_clean.filter(regex=\"IN_|OUT_\").columns\nX = df_clean[feature_cols]\n\nselector = VarianceThreshold(threshold=0.01) \nX_reduced = selector.fit_transform(X)\nselected_features = X.columns[selector.get_support()]\n\ndf_clean = df_clean[selected_features.tolist() + [\"TumorType\"]]\nprint(df_clean.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T23:15:34.430936Z","iopub.execute_input":"2025-12-01T23:15:34.431239Z","iopub.status.idle":"2025-12-01T23:15:34.457825Z","shell.execute_reply.started":"2025-12-01T23:15:34.431215Z","shell.execute_reply":"2025-12-01T23:15:34.457115Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_clean.info()\ndf_clean.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T23:15:52.207081Z","iopub.execute_input":"2025-12-01T23:15:52.207624Z","iopub.status.idle":"2025-12-01T23:15:52.236914Z","shell.execute_reply.started":"2025-12-01T23:15:52.207598Z","shell.execute_reply":"2025-12-01T23:15:52.236296Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = []\nin_features = [f for f in df_clean.columns if f.startswith(\"IN_\")]\n\nfor tumor in df_clean['TumorType'].unique():\n    df_tumor = df_clean[df_clean['TumorType'] == tumor]\n\n    for in_feature in in_features:\n        out_feature = in_feature.replace(\"IN_\", \"OUT_\")\n        if out_feature not in df_tumor.columns:\n            continue\n\n        x = df_tumor[in_feature].astype(float)\n        y = df_tumor[out_feature].astype(float)\n\n        mask = (~x.isna()) & (~y.isna()) & np.isfinite(x) & np.isfinite(y)\n        x_valid, y_valid = x[mask], y[mask]\n\n        if len(x_valid) < 3:  \n            results.append({\n                \"TumorType\": tumor,\n                \"Feature\": in_feature,\n                \"N_pairs\": len(x_valid),\n                \"Wilcoxon_stat\": None,\n                \"P_value\": None,\n                \"Median_IN\": np.median(x_valid) if len(x_valid) > 0 else None,\n                \"Median_OUT\": np.median(y_valid) if len(y_valid) > 0 else None,\n                \"Effect_Direction\": \"Higher_IN\" if np.median(x_valid) > np.median(y_valid) else \"Higher_OUT\"\n            })\n            continue\n\n        stat, pval = wilcoxon(x_valid, y_valid)\n\n        results.append({\n            \"TumorType\": tumor,\n            \"Feature\": in_feature,\n            \"N_pairs\": len(x_valid),\n            \"Wilcoxon_stat\": stat,\n            \"P_value\": pval,\n            \"Median_IN\": np.median(x_valid),\n            \"Median_OUT\": np.median(y_valid),\n            \"Effect_Direction\": \"Higher_IN\" if np.median(x_valid) > np.median(y_valid) else \"Higher_OUT\"\n        })\n\nresults_df = pd.DataFrame(results)\nresults_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T23:17:59.753996Z","iopub.execute_input":"2025-12-01T23:17:59.754544Z","iopub.status.idle":"2025-12-01T23:18:00.228540Z","shell.execute_reply.started":"2025-12-01T23:17:59.754514Z","shell.execute_reply":"2025-12-01T23:18:00.227928Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df[\"EffectSize\"] = np.log2((results_df[\"Median_IN\"] + 1e-8) / \n                                   (results_df[\"Median_OUT\"] + 1e-8))  \nresults_df[\"NegLog10P\"] = -np.log10(results_df[\"P_value\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T23:18:36.329137Z","iopub.execute_input":"2025-12-01T23:18:36.329825Z","iopub.status.idle":"2025-12-01T23:18:36.338320Z","shell.execute_reply.started":"2025-12-01T23:18:36.329799Z","shell.execute_reply":"2025-12-01T23:18:36.337766Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsns.scatterplot(\n    data=results_df,\n    x=\"EffectSize\",\n    y=\"NegLog10P\",\n    hue=\"TumorType\",\n    size=\"NegLog10P\",\n    sizes=(20,200),\n    alpha=0.8\n)\nplt.axhline(-np.log10(0.05), linestyle='--')\nplt.title(\"Volcano Plot Across Tumor Types\")\nplt.xlabel(\"log2( Fold Change IN / OUT )\")\nplt.ylabel(\"-log10(P-value)\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T23:19:07.903207Z","iopub.execute_input":"2025-12-01T23:19:07.903508Z","iopub.status.idle":"2025-12-01T23:19:08.394687Z","shell.execute_reply.started":"2025-12-01T23:19:07.903468Z","shell.execute_reply":"2025-12-01T23:19:08.394067Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\npivot = results_df.pivot_table(\n    index=\"Feature\", \n    columns=\"TumorType\",\n    values=\"Effect_Direction\",\n    aggfunc=lambda x: (x == \"Higher_IN\").mean() \n)\n\nplt.figure(figsize=(14, 10))\n\nsns.heatmap(\n    pivot,\n    annot=True,\n    fmt=\".2f\",\n    linewidths=0.5,\n    linecolor='gray',\n    cmap=\"viridis\", \n    cbar_kws={\"label\": \"Fraction where IN > OUT\"}\n)\n\nplt.title(\"Fraction of Samples Where Feature IN > OUT (per Tumor Type)\", fontsize=16)\nplt.xlabel(\"Tumor Type\", fontsize=14)\nplt.ylabel(\"Radiomic Feature\", fontsize=14)\n\nplt.xticks(rotation=45, ha='right', fontsize=12)\nplt.yticks(fontsize=10) \n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T23:19:53.379350Z","iopub.execute_input":"2025-12-01T23:19:53.379953Z","iopub.status.idle":"2025-12-01T23:19:54.442183Z","shell.execute_reply.started":"2025-12-01T23:19:53.379928Z","shell.execute_reply":"2025-12-01T23:19:54.441406Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.displot(data=results_df, x=\"EffectSize\", hue=\"TumorType\", kind=\"kde\")\nplt.axvline(0, linestyle=\"--\")\nplt.title(\"Effect Size Distribution — IN vs OUT saliency mask\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T23:20:38.746265Z","iopub.execute_input":"2025-12-01T23:20:38.746925Z","iopub.status.idle":"2025-12-01T23:20:39.250424Z","shell.execute_reply.started":"2025-12-01T23:20:38.746899Z","shell.execute_reply":"2025-12-01T23:20:39.249711Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sig = results_df[results_df[\"P_value\"] < 0.01]  \nstrong = sig[abs(sig[\"EffectSize\"]) > 1] \n\n# TOP TEXTURE BIOMARKERS PER TUMOR\ntop = strong.sort_values(\"P_value\").groupby(\"TumorType\").head(10)\ntop","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T23:25:32.234607Z","iopub.execute_input":"2025-12-01T23:25:32.234983Z","iopub.status.idle":"2025-12-01T23:25:32.265741Z","shell.execute_reply.started":"2025-12-01T23:25:32.234958Z","shell.execute_reply":"2025-12-01T23:25:32.265050Z"}},"outputs":[],"execution_count":null}]}